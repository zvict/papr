index: "lego" # this is the name of the experiment
load_path: "" # path to load the model from
save_dir: "./experiments" # folder to save the model to
seed: 1 # random seed
eps: 1.0e-6 # epsilon for numerical stability
use_amp: true # use automatic mixed precision
amp_dtype: "float16"
scaler_min_scale: -1.0  # set a lower bound for the scaler for numerical stability
max_num_pts: 30000 # upper bound of total number of points, set to -1 to disable
dataset:
  mode: "train" # train or test set
  coord_scale: 10.0 # scale the global coordinate by this factor, larger scale helps with geometry details in the point cloud, but not always larger the better
  type: "synthetic" # synthetic (nerf synthetic) or t2 (tanks and temples)
  white_bg: true  # use white or black background
  path: "./data/nerf_synthetic/lego/"
  factor: 1 # downsample the target images by this factor
  batch_size: 1
  shuffle: true
  extract_patch: true # extract patches from the target images
  extract_online: true  # set to false if you have enough memory to load all the patches into memory before training
  read_offline: false # set to true if you have enough memory to load all the images into memory before training
  patches:
    height: 160 # patch height
    width: 160  # patch width
    max_patches: 10 # maximum number of patches to extract from each image (if extract_online is false)
geoms:
  points:
    select_k: 20  # number of top-k nearby points to select from the point cloud for each ray
    select_k_type: "d2r"  # select k points based on their distances to the rays (d2r)
    select_k_sorted: false  # sort the indices of selected points by select_k_type
    load_path: "" # path to load the point cloud from
    init_type: "cube" # initialize the point cloud in a cube or on a sphere ("sphere")
    init_scale: [1.2, 1.2, 1.2] # initial scale of the point cloud, normalized by the coord_scale
    init_center: [0.0, 0.0, 0.0]  # initial center of the point cloud, normalized by the coord_scale
    init_num: 3000 # initial number of points in the point cloud
    influ_init_val: 0.0 # initial influence score of each point
    add_type: "random"  # add points by interpolate add_k points randomly (or "mean", ...)
    add_k: 3  # number of points to interpolate when adding new points
    add_sample_type: "top-knn-std"  # determine where to add new points by sparsity ("top-knn-std") or ...
    add_sample_k: 10  # number of points to consider when measuring sparsity or ...
  background:
    learnable: false  # learn the background color or not
    init_color: [1.0, 1.0, 1.0] # initial background color, normalized by 255
    constant: 5.0 # constant background score
  point_feats:
    dim: 64 # dimension of the point features
    use_inv: true # use as a value feature in the attention layer
    use_ink: false  # use as a key feature in the attention layer
    use_inq: false  # use as a query feature in the attention layer
exposure_control:
  use: false
  shading_code_dim: 128 # dimension of the shading codes
  shading_code_scale: 1.0 # scale the shading codes by this factor, use 8.0 for random generation
  shading_code_num_samples: 20  # number of samples to generate the shading codes
  shading_code_resample_iter: 10000 # number of iterations to resample the shading codes
  shading_code_resample_size: 200 # number of samples to resample the shading codes
  shading_code_resample_select_by: "psnr" # select the best samples by "psnr" or "lpips"
  mapping_mlp:
    num_layers: 8
    dim: 256
    act: "relu"
    last_act: "relu+1"
    use_wn: false
    out_dim: 64
models:
  use_renderer: true  # use the UNet or not, if not, predicted rgb is a fused output of value embedding MLP
  last_act: "none"  # last activation function to normalize the predicted rgb
  normalize_topk_attn: true # normalize the top-k attention weights after softmax
  attn:
    k_type: 1
    q_type: 1
    v_type: 1
    d_model: 256
    score_act: "relu"
    embed:
      embed_type: 1 # 1: positional encoding with input itself, 2: positional encoding without input itself
      k_L: [6, 6, 6]   # order of the positional encoding for each feature in k
      q_L: [6]   # order of the positional encoding for each feature in q
      v_L: [6, 6]  # order of the positional encoding for each feature in v
      pe_factor: 2.0
      pe_mult_factor: 1.0
      key:
        d_ff: 256 # dimension of the hidden layer in the embedding MLP
        d_ff_out: 256 # dimension of the output of the embedding MLP
        n_ff_layer: 5 # number of layers in the embedding MLP
        ff_act: "relu"
        ff_act_a: 1.0
        ff_act_b: 1.0
        ff_act_trainable: false
        ff_last_act: "none" # last activation function in the embedding MLP
        norm: "layernorm"
        dropout_ff: 0.0
        use_wn: false
        residual_ff: false
        skip_layers: []
        half_layers: []
        residual_layers: []
        residual_dims: []
      query:
        d_ff: 256
        d_ff_out: 256
        n_ff_layer: 5
        ff_act: "relu"
        ff_act_a: 1.0
        ff_act_b: 1.0
        ff_act_trainable: false
        ff_last_act: "none"
        norm: "layernorm"
        dropout_ff: 0.0
        use_wn: false
        residual_ff: false
        skip_layers: []
        half_layers: []
        residual_layers: []
        residual_dims: []
      value:
        d_ff: 256
        d_ff_out: 32
        n_ff_layer: 8
        ff_act: "relu"
        ff_act_a: 1.0
        ff_act_b: 1.0
        ff_act_trainable: false
        ff_last_act: "none"
        norm: "none"
        dropout_ff: 0.0
        use_wn: false
        residual_ff: false
        skip_layers: []
        half_layers: []
        residual_layers: []
        residual_dims: []
  renderer: # the UNet
    generator:
      type: "small-unet"
      small_unet:
        bilinear: false
        norm: "none"
        single: true
        last_act: "none"
        affine_layer: -1
training:
  steps: 250000 # number of training steps
  prune_steps: 500  # interval to prune the point cloud
  prune_start: 10000  # start pruning after this step
  prune_stop: 150000  # stop pruning after this step
  prune_thresh: 0.0  # influence score threshold to prune the point cloud
  prune_thresh_list: [] # change the threshold at steps in prune_steps_list, if empty, then use prune_thresh
  prune_steps_list: []
  prune_type: "<" # prune points with influence scores smaller than the threshold ("<") or larger than the threshold (">")
  add_steps: 1000 # interval to add new points
  add_start: 20000  # start adding new points after this step
  add_stop: 70000 # stop adding new points after this step
  add_num: 1000 # number of points to add each time
  add_num_list: []
  add_steps_list: []
  exclude_keys: []  # not loading these parameters when loading the model
  fix_keys: [ # fix these parameters when training the model
    # "points",
    # "pc_norms",
    # # "norm_mlp",
    # "attn",
    # "pc_feats",
    # "attn_mlp",
    # # "renderer",
    # # "bkg_feats",
    # "bkg_points",
    # "points_influ_scores"
    ]
  losses: # loss weights
    mse: 1.0
    lpips: 1.0e-2
    lpips_alex: 0.0
  lr:
    lr_factor: 1.0  # learning rate factor, multiply all the learning rates by this factor
    mapping_mlp:
      type: "none"
      base_lr: 1.0e-6
      factor: 1
      warmup: 0
      weight_decay: 0
    attn:
      type: "cosine-hlfperiod"
      base_lr: 3.0e-4
      factor: 1
      warmup: 10000
      weight_decay: 0
    points:
      type: "cosine"
      base_lr: 2.0e-3
      factor: 1
      warmup: 0
      weight_decay: 0
    bkg_feats:
      type: "none"
      base_lr: 0.0
      factor: 1
      warmup: 10000
      weight_decay: 0
    points_influ_scores:
      type: "cosine-hlfperiod"
      base_lr: 1.0e-3
      factor: 1
      warmup: 10000
      weight_decay: 0
    feats: 
      type: "cosine-hlfperiod"
      base_lr: 1.0e-3
      factor: 1
      warmup: 10000
      weight_decay: 0
    generator:
      type: "cosine-hlfperiod"
      base_lr: 1.0e-4
      factor: 1
      warmup: 10000
      weight_decay: 0
eval:
  dataset:
    name: "testset"
    mode: "test"
    extract_patch: false
    type: "synthetic"
    white_bg: true
    path: "./data/nerf_synthetic/lego/"
    factor: 1
    num_workers: 0
    num_slices: -1
  step: 5000  # evaluate the model every this number of steps
  img_idx: 50 # index of the image to evaluate
  max_height: 100 # maximum size for each loop when rendering a full image, if the image is too large, it will be rendered in multiple loops due to memory constraints
  max_width: 100
  save_fig: true # save the log images during training
test:
  load_path: "" # path to load the model from for testing
  save_fig: true  # save the log images during testing
  save_video: false # save the video during testing
  max_height: 100
  max_width: 100
  datasets:
    - name: "testset"
      mode: "test"
      extract_patch: false
      type: "synthetic"
      white_bg: true
      path: "./data/nerf_synthetic/lego/"
      factor: 1
      num_workers: 0
      num_slices: -1
  plots:  # videos that visualize different components of the model
    pcrgb: true
    featattn: false